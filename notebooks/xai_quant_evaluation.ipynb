{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# If you do some changes in file. jupiter notebook will update saved files \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum.attr as a\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import OurDataset\n",
    "from evaluate import EvaluateExplanation\n",
    "from explain import STS_ExplainWrapper, ExplanationExecuter\n",
    "from compare_docano_XAI import Compare_docano_XAI,Check_docano_XAI, Hyper_optimalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OurDataset(csv_dirpath=\"./data\")\n",
    "file='rationale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=Check_docano_XAI(rationale_dataset_path=f'../data/annotations/{file}.json',xai_dataset=dataset,tuple_indexes=dataset.fact_check_post_mapping) #data=doccano importance_map=xai\n",
    "indexes_doc, indexes_xai, doc_data=check.get_matched_doccano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_dataset=round((0.2/100)*len(indexes_xai))\n",
    "indexes_xai=indexes_xai[:length_dataset]    \n",
    "dataset.fact_check_post_mapping = [dataset.fact_check_post_mapping[i] for i in indexes_xai]\n",
    "# dataset.fact_check_post_mapping = dataset.fact_check_post_mapping[10:100] #smaller ds for testing purposes\n",
    "loader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### layer method ####\n",
    "model = STS_ExplainWrapper.setup_t5_transformer(\"../models/GTR-T5-FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\envs\\projectXAI\\lib\\site-packages\\captum\\attr\\_models\\base.py:191: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#### ordinary method ####\n",
    "model = STS_ExplainWrapper.setup_t5_transformer(\"../models/GTR-T5-FT\",interpretable_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = a.LayerGradientXActivation(model, layer=model.get_embedding_layer())\n",
    "method = a.InputXGradient(model)\n",
    "explain = ExplanationExecuter(method, compute_baseline=False, visualize_explanation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you dont have explanation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = EvaluateExplanation(rationale_path=f\"./results/{file}.json\", verbose=True)\n",
    "final_metric, all_metrics = evaluation.evaluate(loader, explain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': {}, 'plausibility': {'auprc_plau': 0.550458665776}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have explanation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method='Saliency'\n",
    "normalization='without_normalize'\n",
    "method_param={'Saliency':{'parameters': {'abs': False}}}\n",
    "model_param={}\n",
    "\n",
    "explanations=Hyper_optimalization.load_explanations(f'./results/explain_multilingual_e5_model.json',method_param,model_param,method)\n",
    "comparing=Compare_docano_XAI(docano_dataset=doc_data,importance_map=explanations)\n",
    "explanations=comparing.change_token_explanation_to_sentence(model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric: auprc_plau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:00<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric: token_f1_plau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:00<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric: token_iou_plau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:00<00:00, 14.68it/s]\n",
      "c:\\Users\\Dell\\Desktop\\Kinit\\AutoXAI\\notebooks\\../src\\evaluate.py:262: RuntimeWarning: Mean of empty slice.\n",
      "  faithfullness = np.array(list(all_metrics[\"faithfulness\"].values())).mean()\n",
      "c:\\Users\\Dell\\anaconda3\\envs\\projectXAI\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Need to put all methods from text file manually.\n",
    "# Also doesn't matter what method will be put into ExplanationExecuter \n",
    "\n",
    "evaluation = EvaluateExplanation(verbose=True,rationale_path=f'../data/annotations/{file}.json')\n",
    "final_metric, all_metrics = evaluation.evaluate(loader, explain,explanation_maps=explanations,method_name='Input X Gradient')  #tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2615896462751331"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': {'aopc_compr': 0.07188656, 'aopc_suff': 0.934923},\n",
       " 'plausibility': {'auprc_plau': 0.05932348928028465,\n",
       "  'token_f1_plau': 0.0,\n",
       "  'token_iou_plau': 0.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_autoxai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
