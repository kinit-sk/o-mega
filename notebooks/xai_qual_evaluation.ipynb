{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# If you do some changes in file. jupiter notebook will update saved files \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#name file of doccano and explanation maps \n",
    "file='rationale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import captum.attr as a\n",
    "\n",
    "from dataset import OurDataset\n",
    "from explain import STS_ExplainWrapper, ExplanationExecuter_STS, compare_multiple_explanation_methods\n",
    "from check_explanations import Check_docano_XAI \n",
    "from captum._utils.models.linear_model import SkLearnLasso\n",
    "from captum.attr._core.lime import get_exp_kernel_similarity_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = OurDataset(csv_dirpath=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\captum\\attr\\_models\\base.py:191: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = STS_ExplainWrapper.setup_transformer(\"../models/GTR-T5-FT\",'encoder.embed_tokens',interpretable_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embedding layer: setup_t5_transformer.get_embedding_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_eucl_distance = get_exp_kernel_similarity_function('euclidean', kernel_width=450) #related to Lime\n",
    "# TODO more LayerXAI methods need to be tested\",\n",
    "# a.LayerGradientXActivation(model, model.get_embedding_layer())\n",
    "methods = [\n",
    "    a.Lime(model,similarity_func=exp_eucl_distance,interpretable_model=SkLearnLasso(alpha=1e-19)),\n",
    "    a.Saliency(model),\n",
    "    a.Occlusion(model),\n",
    "    a.InputXGradient(model),\n",
    "    a.GuidedBackprop(model),\n",
    "    a.Deconvolution(model),\n",
    "    a.GradientShap(model,multiply_by_inputs=False),\n",
    "    a.KernelShap(model),\n",
    "    a.IntegratedGradients(model),\n",
    "    a.FeatureAblation(model),\n",
    "    a.DeepLift(model),\n",
    "    a.ShapleyValueSampling(model),\n",
    "    # a.GuidedGradCam(model,layer=model.model.hf_transformer.encoder.embed_tokens.embedding),\n",
    "    a.LRP(model)\n",
    "]\n",
    "explain_wrapper_kwargs = [\n",
    "    {\"parameters\":{\"n_samples\":450,'perturbations_per_eval':1}, \"token_groups_for_feature_mask\": True },       ### Lime\n",
    "    {\"parameters\":{\"abs\": True}},                                                 ### Saliency\n",
    "    { \"parameters\":{\"sliding_window_shapes\":(1,1024),'strides':(1,1024)},\"compute_baseline\": True},     ### Occlusion\n",
    "    {},                                                                            ### Input X Gradient\n",
    "    {},                                                                            ### Guided Backprop \"parameters\":{\"Layer\":True}\n",
    "    {},                                                                            ### Deconvolution\n",
    "    {\"compute_baseline\": True, \"parameters\":{'stdevs':1.0,'n_samples':25}},   ### GradientShap\n",
    "    {\"token_groups_for_feature_mask\": True,\"parameters\":{'n_samples':1000}},       ### KernelShap\n",
    "    { \"compute_baseline\": True, \"token_groups_for_feature_mask\": True },\n",
    "    {\"token_groups_for_feature_mask\": True,'parameters':{'n_samples':5}},\n",
    "]\n",
    "method_names = [\n",
    "    \"Lime\",\n",
    "    \"Saliency\",\n",
    "    'Occlusion',\n",
    "    \"Input X Gradient\",\n",
    "    \"Guided Backprop\",\n",
    "    \"Deconvolution\",\n",
    "    'Gradient Shap',\n",
    "    'Kernel Shap'\n",
    "    \"Integrated Gradients\",\n",
    "    \"Feature Ablation\",\n",
    "    \"DeepLift\",\n",
    "    \"Shapley Value Sampling\",\n",
    "    \"LRP\"\n",
    "    # \"GuidedGradCam\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explain_wrappers = []\n",
    "for method, kwargs in zip(methods, explain_wrapper_kwargs):\n",
    "    explain_wrappers.append(\n",
    "        ExplanationExecuter_STS(method,**kwargs)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check=Check_docano_XAI(rationale_dataset_path=f'../data/annotations/{file}.json',xai_dataset=dataset,tuple_indexes=dataset.fact_check_post_mapping) #data=doccano importance_map=xai\n",
    "indexes_doc, indexes_xai, doc_data=check.get_matched_doccano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indexes_xai[0:1]:#visualization\n",
    "    claim, post = dataset[i]\n",
    "    compare_multiple_explanation_methods(explain_wrappers, post, claim, additional_attribution_kwargs= {}, method_names=method_names) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_autoxai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
