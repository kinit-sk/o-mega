{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "from captum.attr._core.lime import get_exp_kernel_similarity_function\n",
    "from captum._utils.models.linear_model import SkLearnLasso\n",
    "from compare_docano_XAI import Hyper_optimalization,Check_docano_XAI,Visualization_opt,Compare_docano_XAI\n",
    "from explain import STS_ExplainWrapper,SentenceTransformerToHF\n",
    "from dataset import OurDataset\n",
    "import architecture\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods=['GAE_Explain','Occlusion','Input X Gradient','Guided Backprop','Feature Ablation','Kernel Shap','Gradient Shap','Lime','Saliency','ConservativeLRP']\n",
    "# normalizations=['mean_var_normalize', 'second_moment_normalize', 'log_normalize','tanh_normalize', 'min_max_normalize', 'log_scale_normalize','log_min_max_normalize','log_mean_normalize','without_normalize']\n",
    "normalizations=['without_normalize']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.1,0.9,{'step':0.1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F_m: LIME, Feature Ablation, Kernel Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param={\n",
    "'Lime': {\n",
    "    'similarity_func':\n",
    "    {\n",
    "    \"function_name\": [\"captum.attr._core.lime.get_exp_kernel_similarity_function\" ],\n",
    "    \"parameters\": {\"distance_mode\": ['cosine',\"euclidean\"], \"kernel_width\": [450,750]},\n",
    "    },\n",
    "    'interpretable_model':{\n",
    "    \"function_name\": [\"captum._utils.models.linear_model.SkLearnLasso\"],# ,\"captum._utils.models.linear_model.LinearModel\"\n",
    "    \"parameters\": {\"alpha\": [1e-19,1e-25]},\n",
    "}\n",
    "},\n",
    "'LayerGradientXActivation':{\"layer\":[[\"model.get_embedding_layer\"]],'multiply_by_inputs':True},\n",
    "'GAE_Explain':{'implemented_method':True,'layers':{'module_path_expressions':[\"hf_transformer.encoder.layer.*.attention.self.dropout\"]}},\n",
    "'ConservativeLRP':{'implemented_method':True,'layers':{'store_A_path_expressions':[\"hf_transformer.embeddings\"],'attent_path_expressions':['hf_transformer.encoder.layer.*.attention.self.dropout'],'norm_layer_path_expressions':[\"hf_transformer.embeddings.LayerNorm\",\"hf_transformer.encoder.layer.*.attention.output.LayerNorm\",\"hf_transformer.encoder.layer.*.output.LayerNorm\"]}},\n",
    "'Occlusion_word_level':{'implemented_method':True}\n",
    "}\n",
    "method_param={\n",
    "'Lime':{\"parameters\":{\"n_samples\":[80,90]}, \"token_groups_for_feature_mask\": True},    ### Lime\n",
    "'Saliency':{\"parameters\":{'abs':[True,False]}},                                                      ### Saliency    \n",
    "'Occlusion':{\"parameters\":{\"sliding_window_shapes\":[(3,1024),(5,1024)],'strides':[(1,1024),(1,512)]},\"compute_baseline\": True},  ### Occlusion,  ,(5,1024)\n",
    "'Input X Gradient':{},                                                                            ### Input X Gradient\n",
    "'Guided Backprop':{},                                                                            ### Guided Backprop\n",
    "'Deconvolution':{},                                                                            ### Deconvolution\n",
    "'Gradient Shap':{\"parameters\":{'stdevs':[0.1,0.9],'n_samples':[10,15]},\"compute_baseline\": True },   ### GradientShap # \n",
    "'Kernel Shap':{\"parameters\":{'n_samples':[80,90]},\"token_groups_for_feature_mask\": True},          ### KernelShap\n",
    "'Feature Ablation':{\"token_groups_for_feature_mask\": True ,\"compute_baseline\": True},\n",
    "'GAE_Explain':{},\n",
    "'ConservativeLRP':{},\n",
    "'Occlusion_word_level':{\"parameters\":{'regex_condition':['',\".,!?;:â€¦\"]}}, # If you want only word put empty string  ''   \n",
    "'Integrated Gradients':{\"parameters\":{'n_steps':[60,40]}},\n",
    "'LayerGradientXActivation':{},                                                   ### LayerXGradient\n",
    "}          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "combinations = Hyper_optimalization.compute_combinations(model_param, method_param, methods, normalizations)\n",
    "print(len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OurDataset(csv_dirpath='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset: 521\n"
     ]
    }
   ],
   "source": [
    "hyper_opt_exp = Hyper_optimalization(rationale_path=f\"./data/annotations/rationale.json\",\n",
    "                                     explanations_path=\"./notebooks/tmp/test_explain_new_model.json\",\n",
    "                                     dataset=dataset,\n",
    "                                     perc=100,\n",
    "                                     model_path= \"intfloat/multilingual-e5-large\",#\"../models/GTR-T5-FT\",   \n",
    "                                     embeddings_module_name='embeddings.word_embeddings',#,#encoder.embed_tokens\n",
    "                                     methods=methods,\n",
    "                                     normalizations=normalizations,\n",
    "                                     explanation_maps_word = True,\n",
    "                                     model_param=model_param,\n",
    "                                     method_param=method_param,\n",
    "                                     plausability_weight=0.5,\n",
    "                                     faithfulness_weight=0.5,\n",
    "                                     multiple_object=False,\n",
    "                                    )\n",
    "print(f'length of dataset: {len(hyper_opt_exp.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available samplers: TPESampler,NSGAIISampler,NSGAIIISampler,BruteForceSampler,GPSampler \n",
    "sampler='BruteForceSampler'\n",
    "best,trials,Visualization_opt=hyper_opt_exp.run_optimization(sampler=sampler,n_trials=25) # ,n_startup_trials=10,seed=1000\n",
    "Visualization_opt.table_counter(save_path_plot='') \n",
    "Visualization_opt.table_sampler(save_path_plot=f'')\n",
    "Visualization_opt.visual_aopc(save_path_plot=f'')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_autoxai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
