{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "from captum.attr._core.lime import get_exp_kernel_similarity_function\n",
    "from captum._utils.models.linear_model import SkLearnLasso\n",
    "from compare_docano_XAI import Hyper_optimalization,Check_docano_XAI,Visualization_opt,Compare_docano_XAI\n",
    "from explain import STS_ExplainWrapper,SentenceTransformerToHF\n",
    "from dataset import OurDataset\n",
    "import architecture\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods=['GAE_Explain','Occlusion','Input X Gradient','Guided Backprop','Feature Ablation','Kernel Shap','Gradient Shap','Lime','Saliency','ConservativeLRP']\n",
    "# normalizations=['mean_var_normalize', 'second_moment_normalize', 'log_normalize','tanh_normalize', 'min_max_normalize', 'log_scale_normalize','log_min_max_normalize','log_mean_normalize','without_normalize']\n",
    "normalizations=['without_normalize']\n",
    "methods=['Gradient Shap']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.1,0.9,{'step':0.1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F_m: LIME, Feature Ablation, Kernel Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param={\n",
    "'Lime': {\n",
    "    'similarity_func':\n",
    "    {\n",
    "    \"function_name\": [\"captum.attr._core.lime.get_exp_kernel_similarity_function\" ],\n",
    "    \"parameters\": {\"distance_mode\": ['cosine',\"euclidean\"], \"kernel_width\": [450,750]},\n",
    "    },\n",
    "    'interpretable_model':{\n",
    "    \"function_name\": [\"captum._utils.models.linear_model.SkLearnLasso\"],# ,\"captum._utils.models.linear_model.LinearModel\"\n",
    "    \"parameters\": {\"alpha\": [1e-19,1e-25]},\n",
    "}\n",
    "},\n",
    "'LayerGradientXActivation':{\"layer\":[[\"model.get_embedding_layer\"]],'multiply_by_inputs':True},\n",
    "'GAE_Explain':{'implemented_method':True,'layers':{'module_path_expressions':[\"hf_transformer.encoder.layer.*.attention.self.dropout\"]}},\n",
    "'ConservativeLRP':{'implemented_method':True,'layers':{'store_A_path_expressions':[\"hf_transformer.embeddings\"],'attent_path_expressions':['hf_transformer.encoder.layer.*.attention.self.dropout'],'norm_layer_path_expressions':[\"hf_transformer.embeddings.LayerNorm\",\"hf_transformer.encoder.layer.*.attention.output.LayerNorm\",\"hf_transformer.encoder.layer.*.output.LayerNorm\"]}},\n",
    "'Occlusion_word_level':{'implemented_method':True}\n",
    "}\n",
    "method_param={\n",
    "'Lime':{\"parameters\":{\"n_samples\":[80,90]}, \"token_groups_for_feature_mask\": True},    ### Lime\n",
    "'Saliency':{\"parameters\":{'abs':[True,False]}},                                                      ### Saliency    \n",
    "'Occlusion':{\"parameters\":{\"sliding_window_shapes\":[(3,1024),(5,1024)],'strides':[(1,1024),(1,512)]},\"compute_baseline\": True},  ### Occlusion,  ,(5,1024)\n",
    "'Input X Gradient':{},                                                                            ### Input X Gradient\n",
    "'Guided Backprop':{},                                                                            ### Guided Backprop\n",
    "'Deconvolution':{},                                                                            ### Deconvolution\n",
    "'Gradient Shap':{\"parameters\":{'stdevs':(0.1,0.9,{'step':0.1}) ,'n_samples':[10,15]},\"compute_baseline\": True },   ### GradientShap # \n",
    "'Kernel Shap':{\"parameters\":{'n_samples':[80,90]},\"token_groups_for_feature_mask\": True},          ### KernelShap\n",
    "'Feature Ablation':{\"token_groups_for_feature_mask\": True ,\"compute_baseline\": True},\n",
    "'GAE_Explain':{},\n",
    "'ConservativeLRP':{},\n",
    "'Occlusion_word_level':{\"parameters\":{'regex_condition':['',\".,!?;:â€¦\"]}}, # If you want only word put empty string  ''   \n",
    "'Integrated Gradients':{\"parameters\":{'n_steps':[60,40]}},\n",
    "'LayerGradientXActivation':{},                                                   ### LayerXGradient\n",
    "}          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "combinations = Hyper_optimalization.compute_combinations(model_param, method_param, methods, normalizations)\n",
    "print(len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OurDataset(csv_dirpath='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset: 16\n"
     ]
    }
   ],
   "source": [
    "hyper_opt_exp = Hyper_optimalization(rationale_path=f\"../data/annotations/rationale.json\",\n",
    "                                     explanations_path=\"./results/.json\",\n",
    "                                     dataset=dataset,\n",
    "                                     perc=100,\n",
    "                                     model_path= \"intfloat/multilingual-e5-large\",#\"../models/GTR-T5-FT\",   \n",
    "                                     embeddings_module_name='embeddings.word_embeddings',#,#encoder.embed_tokens\n",
    "                                     methods=methods,\n",
    "                                     normalizations=normalizations,\n",
    "                                     explanation_maps_sentence = True,\n",
    "                                     model_param=model_param,\n",
    "                                     method_param=method_param,\n",
    "                                     plausability_weight=0.5,\n",
    "                                     faithfulness_weight=0.5,\n",
    "                                     multiple_object=False,\n",
    "                                    )\n",
    "print(f'length of dataset: {len(hyper_opt_exp.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 16:51:20,223] A new study created in memory with name: no-name-b5153e82-85fa-458f-be11-430c1fd05699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stdevs': 0.2, 'n_samples': 15}\n",
      "without_normalize\n",
      "Gradient Shap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-07-03 16:51:25,726] Trial 0 failed with parameters: {'method': 'Gradient Shap', 'normalization': 'without_normalize', 'Gradient Shap-stdevs': 0.2, 'Gradient Shap-n_samples': 15} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1768, in objective\n",
      "    with warnings.catch_warnings():\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1477, in compute_explanation\n",
      "    if method in model_param:\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1391, in set_model\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\explain.py\", line 72, in setup_transformer\n",
      "    transformer = SentenceTransformerToHF(\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\architecture.py\", line 30, in __init__\n",
      "    self.sentence_transformer = SentenceTransformer(model_path)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 95, in __init__\n",
      "    modules = self._load_sbert_model(model_path)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 840, in _load_sbert_model\n",
      "    module = module_class.load(os.path.join(model_path, module_config['path']))\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 137, in load\n",
      "    return Transformer(model_name_or_path=input_path, **config)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 29, in __init__\n",
      "    self._load_model(model_name_or_path, config, cache_dir)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 49, in _load_model\n",
      "    self.auto_model = AutoModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 493, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2700, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 715, in __init__\n",
      "    self.encoder = XLMRobertaEncoder(config)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 478, in __init__\n",
      "    self.layer = nn.ModuleList([XLMRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 478, in <listcomp>\n",
      "    self.layer = nn.ModuleList([XLMRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 400, in __init__\n",
      "    self.output = XLMRobertaOutput(config)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 375, in __init__\n",
      "    self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 112, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 118, in reset_parameters\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\torch\\nn\\init.py\", line 518, in kaiming_uniform_\n",
      "    return tensor.uniform_(-bound, bound, generator=generator)\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-03 16:51:25,772] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6468\\1527671779.py\", line 3, in <module>\n",
      "    best,trials,Visualization_opt=hyper_opt_exp.run_optimization(sampler=sampler,n_trials=1) # ,n_startup_trials=4,seed=1000\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1920, in run_optimization\n",
      "    else:\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n",
      "    _optimize(\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 248, in _run_trial\n",
      "    raise func_err\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1768, in objective\n",
      "    with warnings.catch_warnings():\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1477, in compute_explanation\n",
      "    if method in model_param:\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\compare_docano_XAI.py\", line 1391, in set_model\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\explain.py\", line 72, in setup_transformer\n",
      "    transformer = SentenceTransformerToHF(\n",
      "  File \"c:\\Users\\Dell\\Desktop\\Kinit\\o-mega\\notebooks\\../src\\architecture.py\", line 30, in __init__\n",
      "    self.sentence_transformer = SentenceTransformer(model_path)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 95, in __init__\n",
      "    modules = self._load_sbert_model(model_path)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 840, in _load_sbert_model\n",
      "    module = module_class.load(os.path.join(model_path, module_config['path']))\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 137, in load\n",
      "    return Transformer(model_name_or_path=input_path, **config)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 29, in __init__\n",
      "    self._load_model(model_name_or_path, config, cache_dir)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 49, in _load_model\n",
      "    self.auto_model = AutoModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 493, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2700, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 715, in __init__\n",
      "    self.encoder = XLMRobertaEncoder(config)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 478, in __init__\n",
      "    self.layer = nn.ModuleList([XLMRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 478, in <listcomp>\n",
      "    self.layer = nn.ModuleList([XLMRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 400, in __init__\n",
      "    self.output = XLMRobertaOutput(config)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py\", line 375, in __init__\n",
      "    self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 112, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 118, in reset_parameters\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "  File \"c:\\Users\\Dell\\anaconda3\\envs\\env_autoxai_project\\lib\\site-packages\\torch\\nn\\init.py\", line 518, in kaiming_uniform_\n",
      "    return tensor.uniform_(-bound, bound, generator=generator)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# available samplers: TPESampler,NSGAIISampler,NSGAIIISampler,BruteForceSampler,GPSampler \n",
    "sampler='BruteForceSampler'\n",
    "best,trials,Visualization_opt=hyper_opt_exp.run_optimization(sampler=sampler,n_trials=1) # ,n_startup_trials=4,seed=1000\n",
    "Visualization_opt.table_counter(save_path_plot='./results/count_tables/baseline_counter.csv') \n",
    "Visualization_opt.table_sampler(save_path_plot=f'./results/sampler_tables/baseline_sampler.csv')\n",
    "Visualization_opt.visual_aopc(save_path_plot=f'./results/aopc_plots/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_autoxai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
